<!DOCTYPE html>
<html>

<head>
    <style>
        body,
        html {
            height: 100%;
            margin: 0;
            display: flex;
            align-items: center;
            /* Align button to center of screen */
            justify-content: center;
        }

        #video {
            position: absolute;
            right: 0;
            bottom: 0;
            min-width: 100%;
            min-height: 100%;
            width: auto;
            height: auto;
            z-index: -100;
        }

        #microphone {
            position: relative;
            z-index: 1;
            background-image: url('http://127.0.0.1:8001/mic.png');
            background-size: cover;
            width: 100px;
            /* Double the button size */
            height: 100px;
            /* Double the button size */
            border: none;
            background-color: rgba(0, 0, 0, 0.0);
            /* 半透明な背景色を指定 */
            filter: invert(100%) sepia(100%) saturate(0%) hue-rotate(0deg);
            /* フィルターを適用 */
        }

        #status {
            background-color: rgba(0, 0, 0, 0.5);
            /* 半透明の黒 */
            border-radius: 25px;
            /* 角を丸く */
            color: white;
            /* テキストの色を白に */
            padding: 15px;
            /* テキスト周りの余白 */
        }

        #answer {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 60%;
            height: 60%;
            background-color: rgba(0, 0, 0, 0.5);
            /* 半透明の黒 */
            border-radius: 25px;
            /* 角を丸く */
            color: white;
            /* テキストの色を白に */
            padding: 15px;
            /* テキスト周りの余白 */
            /*overflow: auto;*/
            overflow-y: scroll;
            /* 領域内のコンテンツがオーバーフローした場合にスクロールバーを表示 */
            font-weight: bold;
            /* テキストを太く */
            font-size: 46px;
            /* フォントサイズを大きく */
            word-wrap: break-word;
            /* テキストを折り返す */
            display: none;
            /* 最初は非表示にする */
        }

        #answer img {
            width: 100%;
            /* 画像の幅を領域に合わせる */
            height: auto;
            /* 高さを自動調整して縦横比を維持 */
            object-fit: contain;
            /* 縦横比を維持したまま、領域にフィット */
        }

        #container {
            display: flex;
            align-items: center;
            flex-direction: column;
            position: fixed;
            bottom: 0%;
        }
    </style>
</head>

<body>
    <!-- please get a video from  https://upload.wikimedia.org/wikipedia/commons/transcoded/c/c0/Big_Buck_Bunny_4K.webm/Big_Buck_Bunny_4K.webm.720p.webm -->
    <video id="video" src="http://127.0.0.1:8001/Big_Buck_Bunny_4K.webm.720p.webm" autoplay loop muted></video>
    <div id="answer"></div>
    <div id="container">
        <button id="microphone"></button>
        <p id="status">音声認識を開始してください</p>
    </div>

    <script>
        let isPushedMicButton = false;
        let isSpeechRecognizing = false;
        let isCanceledSpeechRecognition = false;
        let eventSource = null;

        const video = document.getElementById('video');
        const microphone = document.getElementById('microphone');
        microphone.disabled = true; // クリック禁止　スペースのみOK
        const status = document.getElementById('status');
        const answer = document.getElementById('answer');

        window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.lang = 'ja-JP';

        microphone.addEventListener('mousedown', startProcessing);
        microphone.addEventListener('mouseup', stopProcessing);
        window.addEventListener('keydown', (e) => {
            if (e.code === 'Space') startProcessing();
        });
        window.addEventListener('keyup', (e) => {
            if (e.code === 'Space') stopProcessing();
        });

        // 背景動画の音声を再生する 初期値は muted でないとautoplayできないためのダミー処理
        document.addEventListener("mousedown", function () {
            video.play();
            video.muted = false;
        });

        // スクリーンショットを撮影し、画像URLを取得する処理
        function screenshotImage() {
            // スクリーンショットを撮りたい要素を取得する
            const element = document.getElementById("video");

            // キャンバスを作成して要素のサイズに合わせる
            const canvas = document.createElement("canvas");
            canvas.width = element.offsetWidth;
            canvas.height = element.offsetHeight;

            // キャンバスに要素の内容を描画する
            const context = canvas.getContext("2d");
            context.drawImage(element, 0, 0, canvas.width, canvas.height);

            // キャンバスの内容を画像として表示するための新しいイメージ要素を作成
            const image = new Image();
            image.src = canvas.toDataURL(); // キャンバスの内容をデータURLに変換して設定
            return image;
        }

        // element 領域をアニメーションさせながら消す
        //
        // element.style.display = 'none'
        // element.innerHTML=''
        //
        function hide_element_with_animation(element) {
            setTimeout(() => {
                // 画面を半分に縮小
                // 初期の状態を保存
                const initialTransform = element.style.transform;
                const initialTransition = element.style.transition;
                element.style.transform = "scale(0.5)";
                element.style.transition = "transform 0.5s";
                setTimeout(() => {
                    // 要素の状態をリセット
                    element.style.transform = initialTransform;
                    element.style.transition = initialTransition;
                    // 要素を隠す
                    element.style.display = 'none';
                    element.innerHTML = "";
                }, 1500);
            }, 1500);
        }


        recognition.addEventListener('start', function () {
            console.log('音声認識 開始');
            video.muted = true;
        });

        recognition.addEventListener('end', function () {
            console.log('音声認識 終了');
            isSpeechRecognizing = false;
            video.muted = false;
        });

        recognition.addEventListener('nomatch', function (event) {
            // 音声認識が一致しない結果を返した場合の処理
            onsole.log('音声認識 音声認識が一致しない結果を返した');
            isSpeechRecognizing = false;
            video.muted = false;
        });

        recognition.addEventListener('error', function (event) {
            onsole.log('音声認識 エラーが発生');
            isSpeechRecognizing = false;
            video.muted = false;
        });
        // 音声認識の途中結果が利用可能になったときの処理
        //
        // 1. 認識したテキストをChatGPTに送信して回答を受信する
        // 2. ローカルで処理してしまうもの
        // - スクリーンショット処理
        //
        recognition.addEventListener('result', (e) => {
            console.log('音声認識したテキスト:' + e.results[0][0].transcript);
            // 音声認識のためにミュートしていたのを解除
            video.muted = false;
            // キャンセル処理されている場合は処理を中断
            if (isCanceledSpeechRecognition) return;

            // 処理するテキスト
            const text = e.results[0][0].transcript;
            status.innerText = `"${text}" を認識しました`;

            // ローカルでの処理してしまう
            // スクリーンショット
            if (text.includes("スクリーンショット")) {
                console.log("スクリーンショットを実行する");
                // answer 領域を表示する
                answer.style.display = 'block';
                // screenshot を撮影して answerへ表示
                const image = screenshotImage();
                answer.innerHTML = "";
                answer.appendChild(image);
                // status をアップデート
                status.innerText = 'スクリーンショットを撮影しました';
                // answer 領域をアニメーションさせながら消す
                hide_element_with_animation(answer);
                return;
            }

            //
            // 音声読み上げ処理
            //
            const synth = window.speechSynthesis;
            // ストリーム受信したテキストを読み上げるためのバッファとフラグ
            let buffer = ''; // まだ読み上げていない文字を保持するバッファ
            let activeUtterances = 0;  // ストリームできているデータの全ての読み上げが終了したことを判定するためのカウンタ
            let endCallback = null;    // 全ての読み上げが終わった後に呼び出すコールバック関数
            const delimiters = ['。', '.']; // 読み上げを開始するタイミングは デリミタを受信する、もしくはmaxBufferSizeを越えた場合
            const maxBufferSize = 40; // 最大バッファサイズ（これを超えたら読み上げを開始する）

            // 音声読み上げ終了したら表示していたエリアを消す
            function endSpeakCallback() {
                hide_element_with_animation(answer);
            }

            // バッファのデータの読み上げとクリア
            function speakBuffer(callback) {
                // 全ての読み上げが終わった後に呼び出すコールバック関数を設定
                const endCallback = callback;
                // 音声再生前にビデオはミュートしてから再生する
                video.muted = true;
                status.innerText = "[ミュート中]"
                status.innerText = status.innerText + '音声再生中';
                // バッファにデータが残っていたら再生する
                if (buffer.trim() !== '') {
                    const utterThis = new SpeechSynthesisUtterance(buffer);
                    // バッファにデータが残っていたら読み上げを続ける
                    utterThis.onend = () => {
                        // データが残っていれば読み上げる
                        if (buffer !== '') {
                            speakBuffer();
                        }
                        activeUtterances--;
                        if (activeUtterances === 0 && typeof endCallback === 'function') {
                            endCallback();
                            status.innerText = '音声再生終了';
                        }
                    };
                    // speak メソッドを呼び出す前にカウンタをインクリメント
                    activeUtterances++;
                    // 実際の読み上げ処理を行う。バッファ内のデータは読み上げ処理用のバッファに追加済みなのでクリアする
                    synth.speak(utterThis);
                    buffer = '';
                }
            }

            //
            // 認識したテキストをChatGPTに送信して回答を受信する
            // 
            // EventSourceでストリームデータを取得
            eventSource = new EventSource(`http://127.0.0.1:8001/input?text=${encodeURIComponent(text)}`);

            // ストリームで受け取ったデータを画面表示しつつ読み上げる
            eventSource.onmessage = function (event) {
                // const data = event.data;
                // event.dataをJSONにパース
                let jsonData = JSON.parse(event.data);
                const data = jsonData.response;
                // ストリームで受け取ったデータを徐々に表示する
                answer.style.display = 'block';
                answer.innerHTML = answer.innerHTML + data;
                // レスポンス領域を自動スクロール
                answer.scrollTop = answer.scrollHeight;
                // ストリームデータを音声再生
                buffer += data;
                // デリミタが届いたか、バッファが最大サイズを超えたらバッファを読み上げてバッファを空にする
                if (delimiters.includes(data) || buffer.length >= maxBufferSize) {
                    speakBuffer(endSpeakCallback);
                }
            };

            // connection が切れた場合も onerror が呼ばれるので close して自動で再接続を防ぐ
            eventSource.onerror = function (event) {
                console.error('Error occurred:', event);
                eventSource.close();
                // ステータス変更
                status.innerText = 'サーバーとの接続が終了しました。';
                // バッファが残っている場合はすべて読み上げる
                speakBuffer(endSpeakCallback);
                // ボリュームを戻す
                video.muted = false;
            };

            eventSource.onopen = function (event) {
                console.log('Connection opened');
                status.innerText = `"${text}" をサーバーに送信しています...`;
            };
        });

        function startProcessing() {
            // Micボタンは一度 Down すると UP するまで再度 Down できない
            if (isPushedMicButton) return;
            isPushedMicButton = true;
            // 音声入力中の場合は無視する
            if (isSpeechRecognizing) return;
            // 
            // すでに動いている処理をキャンセル
            //
            // 読み上げ中なら読み上げをキャンセルする
            if (window.speechSynthesis.speaking) {
                window.speechSynthesis.cancel();
                console.log('読み上げをキャンセルしました');
                status.innerText = '読み上げをキャンセルしました';
                video.muted = false;
            }
            // ネットワークが接続中なら切る
            if (eventSource && eventSource.readyState !== EventSource.CLOSED) {
                console.log('ネットワーク接続の強制切断');
                eventSource.close();

            }
            // answer 画面が表示されている場合は消す
            if (answer.style.display != 'none'){
                answer.innerText = "";
                answer.style.display = 'none';
            }
            //
            // 音声認識処理
            //
            isSpeechRecognizing = true;
            isCanceledSpeechRecognition = false;
            // Micボタンの色味変更
            microphone.style.filter = "brightness(0%) sepia(1000%) hue-rotate(0deg)";
            video.muted = true;
            status.innerText = "[ミュート中]"
            status.innerText = status.innerText + '音声認識を開始しています...';
            console.log('音声認識を開始する');
            recognition.start();
        }

        function stopProcessing() {
            // Micボタンは一度 Down すると UP するまで再度 Down できない
            isPushedMicButton = false;
            microphone.style.filter = "invert(100%) sepia(100%) saturate(0%) hue-rotate(0deg)";
            // 音声入力中の場合はキャンセル処理
            if (isSpeechRecognizing) {
                console.log('音声認識をキャンセルする');
                recognition.stop();
                isCanceledSpeechRecognition = true;
                status.innerText = '音声認識処理をキャンセルしました';
                return;
            }
        }

    </script>
</body>

</html>